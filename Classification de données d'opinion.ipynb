{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de documents d'opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importations des bibliotèques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etape d'ouverture ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obviously made to show famous 1950s stripper M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film was more effective in persuading me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unless you are already familiar with the pop s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From around the time Europe began fighting Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im not surprised that even cowgirls get the bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(48 out of 278 people found this comment usefu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Went to watch this movie expecting a 'nothing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A good cast and they do their best with what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The only thing that kept me from vomiting afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I just watched this film 15 minutes ago, and I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avis\n",
       "0  Obviously made to show famous 1950s stripper M...\n",
       "1  This film was more effective in persuading me ...\n",
       "2  Unless you are already familiar with the pop s...\n",
       "3  From around the time Europe began fighting Wor...\n",
       "4  Im not surprised that even cowgirls get the bl...\n",
       "5  (48 out of 278 people found this comment usefu...\n",
       "6  Went to watch this movie expecting a 'nothing ...\n",
       "7  A good cast and they do their best with what t...\n",
       "8  The only thing that kept me from vomiting afte...\n",
       "9  I just watched this film 15 minutes ago, and I..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import nltk \n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl=WordNetLemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des dataframesg\n",
    "- [x] Ouverture du dataset \n",
    "- [x] Ouverture des labels\n",
    "* Ouverture du csv sur 10 lines pour éviter des temps de calculs trop long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création ok\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/dataset.csv', sep='\\t', header = None, names = [\"Avis\"], nrow=10)\n",
    "labels = pd.read_csv('Data/labels.csv', sep='\\t', header = None, names = ['Note'])\n",
    "#sns.heatmap(df.isnull(), cbar=False)\n",
    "all = pd.concat([df.Avis,labels.Note], sort =True)\n",
    "\n",
    "print(\"Création ok\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(all)\n",
    "#sns.heatmap(df.isnull(), cbar=False)\n",
    "#all.hist(bins=50, figsize =(7,3))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitements des dataframes\n",
    "\n",
    "- [x] Caster de panda.serie en string\n",
    "- [x] Mettre en minuscule\n",
    "- [x] Sent_tokenize\n",
    "- [x] Word_tokenize\n",
    "- [x] Supression des stop-words et ponctuations merdique\n",
    "- [x] lemmatisation ( marche seulement si je ne fais pas les tags en même temps)\n",
    "- [ ] Faire tag + lemmatisation\n",
    "- [ ] Faire lemmatisation + tag\n",
    "- [ ] Faire tag + stematisation\n",
    "- [ ] Faire stematisation + tag\n",
    "- [ ] Utilisation de treetagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps écoulé pour ce traitement a prit :  0.14011240005493164\n",
      "['obviously', 'made', 'show', 'famous', '1950s', 'stripper', 'misty', 'ayers', '``', 'acting', \"''\", 'talents']\n"
     ]
    }
   ],
   "source": [
    "dfc=df.Avis.copy()\n",
    "debut = time.time()\n",
    "for i in range(0, len(df)-1, 1):\n",
    "\tdfc[i]=''.join(dfc[i]).lower() #jusqu'ici c'est une liste\n",
    "\tdfc[i]=sent_tokenize(dfc[i])# ici cast de la liste en string(avis entier)\n",
    "\tfor j in range(0, len(dfc.loc[i])-1, 1):\n",
    "\t\tdfc.loc[i][j]= contractions.fix(dfc.loc[i][j])\n",
    "\t\tdfc.loc[i][j]=dfc.loc[i][j].lower()\n",
    "\t\tdfc.loc[i][j]=word_tokenize(dfc.loc[i][j])\n",
    "\t\tsentence = dfc.loc[i][j]\n",
    "\t\tsentence_without_sw = sentence# creation d'une liste de phrase tmp\n",
    "\t\tfor word in sentence:\n",
    "\t\t\t#word = nltk.pos_tag(wnl.lemmatize(word, pos='v'))\n",
    "\t\t\tfor sw in stop_words:\n",
    "\t\t\t\tif word==sw or word==\".\" or word==\":\" or word==\",\" or word==\";\":\n",
    "\t\t\t\t\tif word in sentence_without_sw:\n",
    "\t\t\t\t\t\tsentence_without_sw.remove(word)\n",
    "\t\tsentence = sentence_without_sw #permet de retirer les stop word sans changer la longueur de la liste\n",
    "fin = time.time()\n",
    "print(\"Le temps écoulé pour ce traitement a prit : \", fin-debut)\n",
    "print(dfc[0][0]) \n",
    "#1 ere ligne bien parsé mais pas taggé => ['obviously', 'made', 'show', 'famous', '1950s', 'stripper',\n",
    "#'misty', 'ayers', '``', 'acting', \"''\", 'talents']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
