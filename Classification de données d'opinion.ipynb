{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de documents d'opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importations des bibliotèques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import nltk \n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl=WordNetLemmatizer()\n",
    "from nltk.stem.cistem import Cistem\n",
    "stem = Cistem()\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des dataframesg\n",
    "- [x] Ouverture du dataset \n",
    "- [x] Ouverture des labels\n",
    "* Ouverture du csv sur 10 lines pour éviter des temps de calculs trop long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obviously made to show famous 1950s stripper M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film was more effective in persuading me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unless you are already familiar with the pop s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From around the time Europe began fighting Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im not surprised that even cowgirls get the bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(48 out of 278 people found this comment usefu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Went to watch this movie expecting a 'nothing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A good cast and they do their best with what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The only thing that kept me from vomiting afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I just watched this film 15 minutes ago, and I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Avis\n",
       "0  Obviously made to show famous 1950s stripper M...\n",
       "1  This film was more effective in persuading me ...\n",
       "2  Unless you are already familiar with the pop s...\n",
       "3  From around the time Europe began fighting Wor...\n",
       "4  Im not surprised that even cowgirls get the bl...\n",
       "5  (48 out of 278 people found this comment usefu...\n",
       "6  Went to watch this movie expecting a 'nothing ...\n",
       "7  A good cast and they do their best with what t...\n",
       "8  The only thing that kept me from vomiting afte...\n",
       "9  I just watched this film 15 minutes ago, and I..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/dataset.csv', sep='\\t', header = None, names = [\"Avis\"], nrows=10)\n",
    "labels = pd.read_csv('Data/labels.csv', sep='\\t', header = None, names = ['Note'])\n",
    "#sns.heatmap(df.isnull(), cbar=False)\n",
    "all = pd.concat([df.Avis,labels.Note], sort =True)\n",
    "\n",
    "print(\"Création ok\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(all)\n",
    "#sns.heatmap(df.isnull(), cbar=False)\n",
    "#all.hist(bins=50, figsize =(7,3))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitements des dataframes\n",
    "\n",
    "- [x] Caster de panda.serie en string\n",
    "- [x] Mettre en minuscule\n",
    "- [x] Sent_tokenize\n",
    "- [x] Word_tokenize\n",
    "- [x] Supression des stop-words et ponctuations merdique\n",
    "- [x] lemmatisation ( marche seulement si je ne fais pas les tags en même temps)\n",
    "- [ ] Faire tag + lemmatisation\n",
    "- [ ] Faire lemmatisation + tag\n",
    "- [ ] Faire tag + stematisation\n",
    "- [ ] Faire stematisation + tag\n",
    "- [ ] Utilisation de treetagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag avec NLTK et lemmatization après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('obviously', 'RB'),\n",
       "  ('made', 'VBD'),\n",
       "  ('show', 'NN'),\n",
       "  ('famous', 'JJ'),\n",
       "  ('1950s', 'CD'),\n",
       "  ('stripper', 'NN'),\n",
       "  ('misty', 'NN'),\n",
       "  ('ayers', 'NNS'),\n",
       "  ('``', '``'),\n",
       "  ('acting', 'VBG'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('talents', 'NNS')],\n",
       " [('bad', 'JJ'),\n",
       "  ('can', 'MD'),\n",
       "  ('act.boring', 'VBG'),\n",
       "  ('little', 'JJ'),\n",
       "  ('tale', 'JJ'),\n",
       "  ('sweet', 'JJ'),\n",
       "  ('innocent', 'JJ'),\n",
       "  ('sally', 'RB'),\n",
       "  ('(', '('),\n",
       "  ('ayers', 'NNS'),\n",
       "  (')', ')'),\n",
       "  ('drugged', 'VBD'),\n",
       "  ('forced', 'VBN'),\n",
       "  ('white', 'JJ'),\n",
       "  ('slavery', 'NN'),\n",
       "  ('(', '('),\n",
       "  ('prostitution', 'NN'),\n",
       "  (')', ')')],\n",
       " [('she', 'PRP'),\n",
       "  ('meets', 'VBZ'),\n",
       "  ('likable', 'JJ'),\n",
       "  ('tommy', 'JJ'),\n",
       "  ('cole', 'NN'),\n",
       "  ('instantly', 'RB'),\n",
       "  ('falls', 'VBZ'),\n",
       "  ('love', 'IN'),\n",
       "  ('her', 'PRP$')],\n",
       " [('wants', 'VBZ'),\n",
       "  ('help', 'NN'),\n",
       "  ('escape', 'NN'),\n",
       "  ('can', 'MD'),\n",
       "  ('?', '.')],\n",
       " [('really', 'RB'),\n",
       "  ('not', 'RB'),\n",
       "  ('care.there', 'VB'),\n",
       "  ('no', 'DT'),\n",
       "  ('real', 'JJ'),\n",
       "  ('skin', 'NN'),\n",
       "  ('--', ':'),\n",
       "  ('ayers', 'NNS'),\n",
       "  ('strips', 'VBP'),\n",
       "  ('slowly', 'RB'),\n",
       "  ('her', 'PRP$'),\n",
       "  ('underwear', 'JJ'),\n",
       "  ('(', '('),\n",
       "  ('twice', 'RB'),\n",
       "  (')', ')')],\n",
       " [('rest', 'NN'),\n",
       "  ('just', 'RB'),\n",
       "  ('boring', 'JJ'),\n",
       "  ('little', 'JJ'),\n",
       "  ('tale', 'JJ'),\n",
       "  ('chockful', 'JJ'),\n",
       "  ('bad', 'JJ'),\n",
       "  ('acting', 'VBG'),\n",
       "  ('atrocious', 'JJ'),\n",
       "  ('``', '``'),\n",
       "  ('comedy', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('(', '('),\n",
       "  ('never', 'RB'),\n",
       "  ('thought', 'VBN'),\n",
       "  ('prostitution', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('funny', 'JJ'),\n",
       "  ('what', 'WP'),\n",
       "  ('i', 'NN'),\n",
       "  ('know', 'VBP'),\n",
       "  ('?', '.'),\n",
       "  (')', ')')],\n",
       " [('terrible', 'JJ'), ('post-dubbed', 'JJ'), ('dialogue', 'NN')],\n",
       " [('admit', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('twist', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('end', 'NN'),\n",
       "  ('did', 'VBD'),\n",
       "  ('see', 'VB'),\n",
       "  ('coming', 'VBG'),\n",
       "  ('that', 'IN'),\n",
       "  ('not', 'RB'),\n",
       "  ('enough', 'RB'),\n",
       "  ('sit', 'NN'),\n",
       "  ('this', 'DT')],\n",
       " [('also', 'RB'),\n",
       "  ('ayers', 'NNS'),\n",
       "  (\"'\", 'POS'),\n",
       "  ('attempts', 'NNS'),\n",
       "  ('acting', 'VBG'),\n",
       "  ('hysterical', 'NN'),\n",
       "  ('!', '.')],\n",
       " [('real', 'JJ'), ('bomb', 'NN')],\n",
       " [('avoid', 'NN')]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps écoulé pour ce traitement a prit :  0.27730393409729004\n"
     ]
    }
   ],
   "source": [
    "dfc=df.Avis.copy()\n",
    "debut = time.time() \n",
    "for i in range(0, len(df)-1, 1):\n",
    "    dfc[i]=''.join(dfc[i]).lower() #jusqu'ici c'est une liste\n",
    "    dfc[i]=sent_tokenize(dfc[i])# ici cast de la liste en string(avis entier)\n",
    "    for j in range(0, len(dfc.loc[i]), 1):\n",
    "        dfc.loc[i][j]= contractions.fix(dfc.loc[i][j])\n",
    "        dfc.loc[i][j]=dfc.loc[i][j].lower()\n",
    "        dfc.loc[i][j]=word_tokenize(dfc.loc[i][j])\n",
    "        sentence = dfc.loc[i][j]\n",
    "        sentence_without_sw = sentence# creation d'une liste de phrase tmp\n",
    "        for word in sentence:\n",
    "            \n",
    "            word=lemmatizer.lemmatize(word)\n",
    "            \n",
    "            for sw in stop_words:\n",
    "                if word==sw or word==\".\" or word==\":\" or word==\",\" or word==\";\":\n",
    "                    if word in sentence_without_sw:\n",
    "                        sentence_without_sw.remove(word)\n",
    "        sentence = sentence_without_sw\n",
    "        dfc.loc[i][j] = nltk.pos_tag(sentence) #permet de retirer les stop word sans changer la longueur de la listen \n",
    "        \n",
    "   \n",
    "global_string =\"\"\n",
    "display(dfc[0])\n",
    "\n",
    "\n",
    "\n",
    "fin = time.time()\n",
    "print(\"Le temps écoulé pour ce traitement a prit : \", fin-debut)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag avec Treetagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/treetaggerwrapper.py:740: FutureWarning: Possible nested set at position 8\n",
      "  re.IGNORECASE | re.VERBOSE)\n",
      "/usr/lib/python3.7/site-packages/treetaggerwrapper.py:2044: FutureWarning: Possible nested set at position 152\n",
      "  re.VERBOSE | re.IGNORECASE)\n",
      "/usr/lib/python3.7/site-packages/treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/usr/lib/python3.7/site-packages/treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import treetaggerwrapper\n",
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG= \"en\", TAGDIR=\"/home/denozi/treetagger\")\n",
    "\n",
    "\n",
    "dfc=df.Avis.copy()\n",
    "debut = time.time()\n",
    "\n",
    "for i in range(0, len(df)-1, 1):\n",
    "    dfc[i]=''.join(dfc[i]).lower() #jusqu'ici c'est une liste\n",
    "    dfc[i]=sent_tokenize(dfc[i])# ici cast de la liste en string(avis entier)\n",
    "    for j in range(0, len(dfc.loc[i]), 1):\n",
    "        dfc.loc[i][j]= contractions.fix(dfc.loc[i][j])\n",
    "        dfc.loc[i][j]=dfc.loc[i][j].lower()\n",
    "        dfc.loc[i][j]=word_tokenize(dfc.loc[i][j])\n",
    "        sentence = dfc.loc[i][j]\n",
    "        sentence_without_sw = sentence# creation d'une liste de phrase tmp\n",
    "        for word in sentence:\n",
    "            for sw in stop_words:\n",
    "                if word==sw or word==\".\" or word==\":\" or word==\",\" or word==\";\":\n",
    "                    if word in sentence_without_sw:\n",
    "                        sentence_without_sw.remove(word)\n",
    "        dfc.loc[i][j] = tagger.tag_text(sentence_without_sw) #permet de retirer les stop word sans changer la longueur de la listen \n",
    "\n",
    "\n",
    "\n",
    "for avis in dfc:\n",
    "    global_phrase=[]\n",
    "    for phrase in avis:\n",
    "        global_mot=\"\"\n",
    "        for mot in phrase:\n",
    "            mot = mot.split(\"\\t\")\n",
    "            global_string=global_string + (mot[0])+\" \"\n",
    "        global_phrase.append(global_string)\n",
    "        print(global_phrase)\n",
    "        \n",
    "#print(global_string)\n",
    "        \n",
    "        \n",
    "fin = time.time()\n",
    "print(\"Le temps écoulé pour ce traitement a prit : \", fin-debut)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
