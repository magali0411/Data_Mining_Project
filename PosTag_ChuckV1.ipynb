{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Projet Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#import contractions\n",
    "import nltk \n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Importation des datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obviously made to show famous 1950s stripper M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film was more effective in persuading me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unless you are already familiar with the pop s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From around the time Europe began fighting Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im not surprised that even cowgirls get the bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(48 out of 278 people found this comment usefu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Went to watch this movie expecting a 'nothing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A good cast and they do their best with what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The only thing that kept me from vomiting afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I just watched this film 15 minutes ago, and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>There are two reasons why I did not give a 1 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Man In The Attic is a movie set in the 191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>During a sleepless night, I was switching thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>No,Basically your watching something that does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I am dumbfounded that I actually sat and watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In an otherwise good review, loleralacartelort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This version of \"Moby Dick\" insults the audien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>In a summer that also boasted such repugnant s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The dudes at MST3K should see this dog of a fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A mediocre Sci-Fi Channel original picture. A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 187,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/dataset.csv', sep='\\t', header = None, names = [\"Avis\"], nrows=20)\n",
    "labels = pd.read_csv('Data/labels.csv', sep='\\t', header = None, names = ['Note'])\n",
    "#sns.heatmap(df.isnull(), cbar=False)\n",
    "all = pd.concat([df.Avis,labels.Note], sort =True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Etape 1 : Rechercher les meilleurs pré-traitements et les meilleurs classifieurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dans cette étape vous pourrez effectuer différents prétraitements et utiliser différents classifieurs\n",
    "afin de rechercher ceux qui sont les plus efficaces. Il ne faut pas hésiter à utiliser différents\n",
    "classifieurs car un classifieur qui s’avère efficace sur un jeu de données est peut être inefficace sur\n",
    "un autre jeu de données. Attention également à l’évaluation de vos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2) Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps écoulé pour ce traitement a prit :  0.6100101470947266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['mediocre', 'sci-fi', 'channel', 'original', 'picture'],\n",
       " ['little', 'squirmish', 'but', 'much'],\n",
       " ['nuclear', 'powered', 'submarine', 'u.s.s'],\n",
       " ['jimmy',\n",
       "  'carter',\n",
       "  'on',\n",
       "  'mission',\n",
       "  'deep',\n",
       "  'thick',\n",
       "  'frigid',\n",
       "  'ice',\n",
       "  'near',\n",
       "  'north',\n",
       "  'pole',\n",
       "  'it',\n",
       "  'attacked',\n",
       "  'giant',\n",
       "  'super',\n",
       "  'charged',\n",
       "  'electric',\n",
       "  'eels'],\n",
       " ['member',\n",
       "  'the',\n",
       "  'crew',\n",
       "  'simmone',\n",
       "  'jade',\n",
       "  'mackinnon',\n",
       "  'thinks',\n",
       "  'has',\n",
       "  'devised',\n",
       "  'way',\n",
       "  'communicate',\n",
       "  'the',\n",
       "  'monsters',\n",
       "  'but',\n",
       "  'not',\n",
       "  'given',\n",
       "  'much',\n",
       "  'chance',\n",
       "  'vague',\n",
       "  'reasons'],\n",
       " ['also',\n",
       "  'among',\n",
       "  'crew',\n",
       "  ':',\n",
       "  'david',\n",
       "  'keith',\n",
       "  'mark',\n",
       "  'sheppard',\n",
       "  'sean',\n",
       "  'whalen'],\n",
       " ['movie',\n",
       "  'could',\n",
       "  'been',\n",
       "  'somewhat',\n",
       "  'better',\n",
       "  'the',\n",
       "  'eels/monsters',\n",
       "  'not',\n",
       "  'cartoonish']]"
      ]
     },
     "execution_count": 188,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc=df.Avis.copy()\n",
    "dfc_phrases = df.Avis.copy()\n",
    "\n",
    "debut = time.time()\n",
    "for i in range(0, len(df), 1):\n",
    "    \n",
    "    dfc[i]=''.join(dfc[i]).lower() #jusqu'ici c'est une liste\n",
    "    dfc[i]=sent_tokenize(dfc[i])# ici cast de la liste en string(avis entier)\n",
    "    dfc_phrases[i] = dfc[i] # Ici on va chuck nos phrase et apposer nos tag\n",
    "\n",
    "    for j in range(0, len(dfc.loc[i]), 1):\n",
    "        \n",
    "        #dfc.loc[i][j]= contractions.fix(dfc.loc[i][j])\n",
    "        dfc.loc[i][j]=dfc.loc[i][j].lower()\n",
    "        dfc.loc[i][j]=word_tokenize(dfc.loc[i][j])\n",
    "        sentence = dfc.loc[i][j]\n",
    "        sentence_without_sw = sentence# creation d'une liste de phrase tmp\n",
    "        for word in sentence:\n",
    "            #word = nltk.pos_tag(wnl.lemmatize(word, pos='v'))\n",
    "            for sw in stop_words:\n",
    "                if word==sw or word==\".\" or word==\":\" or word==\",\" or word==\";\" or word==')' or word =='(':\n",
    "                    if word in sentence_without_sw:\n",
    "                        sentence_without_sw.remove(word)\n",
    "        sentence = sentence_without_sw #permet de retirer les stop word sans changer la longueur de la liste\n",
    "fin = time.time()\n",
    "print(\"Le temps écoulé pour ce traitement a prit : \", fin-debut)\n",
    "display(dfc_phrases[19]) \n",
    "#1 ere ligne bien parsé mais pas taggé => ['obviously', 'made', 'show', 'famous', '1950s', 'stripper',\n",
    "#'misty', 'ayers', '``', 'acting', \"''\", 'talents']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Création d'une liste de StopWords et mots à supprimer de tous nos commentaires car inutiles !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tag des mots & chunking & chanking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "L'ajout de tag aux mots est très important car il permet de leur donner un certain poid lors de l'analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Tag des mots sur le dataframe\n",
    "\n",
    "from nltk import pos_tag\n",
    "token = []\n",
    "for i in range(0, len(dfc), 1):\n",
    "    for j in range(0, len(dfc[i]), 1):\n",
    "        token = pos_tag(dfc_phrases[i][j])\n",
    "        dfc_phrases[i][j] = token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "#nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#def TagNLTK(df):\n",
    "#    token = []\n",
    "#    dfc = df.copy()\n",
    "#    for i in range(0, len(df), 1):\n",
    "#        for j in range(0, len(df[i]), 1):\n",
    "#            token = pos_tag(df[i][j])\n",
    "#            dfc[i][j] = token\n",
    "#    return dfc\n",
    "\n",
    "#TagNLTK(dfc_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Liste de tag qui sont à enlever \n",
    "\n",
    "NLTK_LIST = ['.','$','\\'','(',')',':','CC','CD','DT','EX','FW','IN','LS','SYM','TO','WP',r'NPP.?','POS','PDT',r'PRP.?','RP','WTD','WP','WRB','\"']\n",
    "\n",
    "\n",
    "\n",
    "TREE_TAG_LIST = ['PUN:cit','PRP:det','PRO:rel','PRP:det','PRP', r'PRO', 'NUM','KON',r'DET']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before'"
      ]
     },
     "execution_count": 196,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('however', 'RB'), ('many', 'JJ'), ('scenes', 'NNS'), ('were', 'VBD'), ('somehow', 'RB'), ('blocked', 'VBN'), ('the', 'DT'), ('bad', 'JJ'), ('scripting.the', 'NN'), ('reason', 'NN'), ('the', 'DT'), ('cool', 'NN'), ('idea', 'NN'), ('looking', 'VBG'), ('the', 'DT'), ('cyborg', 'NN'), ('which', 'WDT'), ('quite', 'RB'), ('different', 'JJ'), ('most', 'JJS'), ('such', 'JJ'), ('roles', 'NNS'), (\"'ve\", 'VBP'), ('seen', 'VBN'), ('far.everything', 'VBG'), ('else', 'RB'), ('this', 'DT'), ('movie', 'NN'), ('bad', 'JJ'), ('as', 'IN'), ('it', 'PRP'), ('be', 'VB')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'After'"
      ]
     },
     "execution_count": 196,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['however', 'many', 'scenes', 'were', 'somehow', 'blocked', 'bad', 'scripting.the', 'reason', 'cool', 'idea', 'looking', 'cyborg', 'which', 'quite', 'different', 'most', 'such', 'roles', \"'ve\", 'seen', 'far.everything', 'else', 'movie', 'bad', 'it', 'be']\n"
     ]
    }
   ],
   "source": [
    "# Nouveau df avec seulement les mots qui ne sont pas dans la liste\n",
    "\n",
    "dfc_phrases_clear = dfc_phrases.copy()\n",
    "\n",
    "display(\"Before\")\n",
    "print(dfc_phrases[10][2])\n",
    "\n",
    "\n",
    "for i in range(0, len(dfc_phrases_clear), 1):\n",
    "    for j in range(0, len(dfc_phrases_clear.loc[i]), 1):\n",
    "        dfc_phrases_clear[i][j] = ([word for word,pos in dfc_phrases_clear[i][j] if (pos not in NLTK_LIST)])\n",
    "\n",
    "display(\"After\")\n",
    "print(dfc_phrases_clear[10][2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Suprression des mots trop rares, trop fréquents et stop words**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "STOPWORDS = set([\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"ain\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can\",\"could\",\"did\",\"do\",\"does\",\"doesn\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"her\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"i\",\"I\",\"if\",\"in\",\"into\",\"is\",\"isn\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"just\",\"ll\",\"m\",\"ma\",\"me\",\"mightn\",\"mightn't\",\"more\",\"most\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"needn\",\"needn't\",\"no\",\"nor\",\"not\",\"now\",\"o\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"re\",\"s\",\"same\",\"shan\",\"shan't\",\"she\",\"she's\",\"should\",\"should've\",\"shouldn\",\"shouldn't\",\"so\",\"some\",\"such\",\"t\",\"than\",\"that\",\"that'll\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"ve\",\"very\",\"was\",\"wasn\",\"wasn't\",\"we\",\"were\",\"weren\",\"weren't\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"won\",\"won't\",\"wouldn\",\"wouldn't\",\"y\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"could\",\"he'd\",\"he'll\",\"he's\",\"here's\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"let's\",\"ought\",\"she'd\",\"she'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"what's\",\"when's\",\"where's\",\"who's\",\"why's\",\"would\",\"able\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"afterwards\",\"ah\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"among\",\"amongst\",\"announce\",\"another\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"arent\",\"arise\",\"around\",\"aside\",\"ask\",\"asking\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"became\",\"become\",\"becomes\",\"becoming\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"believe\",\"beside\",\"besides\",\"beyond\",\"biol\",\"brief\",\"briefly\",\"c\",\"ca\",\"came\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"couldnt\",\"date\",\"different\",\"done\",\"downwards\",\"due\",\"e\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"happens\",\"hardly\",\"hed\",\"hence\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hes\",\"hi\",\"hid\",\"hither\",\"home\",\"howbeit\",\"however\",\"hundred\",\"id\",\"ie\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"invention\",\"inward\",\"itd\",\"it'll\",\"j\",\"k\",\"keep\",\"keeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"moreover\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"normally\",\"nos\",\"noted\",\"nowhere\",\"obtain\",\"obtained\",\"obviously\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"one\",\"ones\",\"onto\",\"ord\",\"others\",\"otherwise\",\"outside\",\"overall\",\"owing\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"said\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"shed\",\"shes\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"thats\",\"that've\",\"thence\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"theyd\",\"theyre\",\"think\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"together\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"unto\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"wasnt\",\"way\",\"wed\",\"welcome\",\"went\",\"werent\",\"whatever\",\"what'll\",\"whats\",\"whence\",\"whenever\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"whim\",\"whither\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whomever\",\"whos\",\"whose\",\"widely\",\"willing\",\"wish\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"would\",\"www\",\"x\",\"yes\",\"yet\",\"youd\",\"youre\",\"z\",\"zero\",\"a's\",\"allow\",\"allows\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"associated\",\"best\",\"better\",\"c'mon\",\"c's\",\"cant\",\"changes\",\"clearly\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"corresponding\",\"course\",\"currently\",\"definitely\",\"described\",\"despite\",\"entirely\",\"exactly\",\"example\",\"going\",\"greetings\",\"hello\",\"help\",\"hopefully\",\"ignored\",\"inasmuch\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"it'd\",\"keep\",\"keeps\",\"novel\",\"presumably\",\"reasonably\",\"second\",\"secondly\",\"sensible\",\"serious\",\"seriously\",\"sure\",\"t's\",\"third\",\"thorough\",\"thoroughly\",\"three\",\"well\",\"wonder\",\"do\",\"am\",\"were\",\"be\",\"been\", \"being\", \"have\", \"has\",\"?\",\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obviously': 2,\n",
       " 'made': 10,\n",
       " 'show': 6,\n",
       " 'famous': 4,\n",
       " 'stripper': 1,\n",
       " 'misty': 1,\n",
       " 'ayers': 4,\n",
       " '``': 38,\n",
       " 'acting': 11,\n",
       " \"''\": 38,\n",
       " 'talents': 1,\n",
       " 'bad': 7,\n",
       " 'ca': 4,\n",
       " \"n't\": 31,\n",
       " 'act.boring': 1,\n",
       " 'little': 6,\n",
       " 'tale': 3,\n",
       " 'sweet': 1,\n",
       " 'innocent': 1,\n",
       " 'sally': 1,\n",
       " 'being': 4,\n",
       " 'drugged': 1,\n",
       " 'forced': 1,\n",
       " 'white': 1,\n",
       " 'slavery': 1,\n",
       " 'prostitution': 2,\n",
       " 'she': 3,\n",
       " 'meets': 1,\n",
       " 'likable': 2,\n",
       " 'tommy': 1,\n",
       " 'cole': 1,\n",
       " 'instantly': 1,\n",
       " 'falls': 1,\n",
       " 'her': 5,\n",
       " 'wants': 4,\n",
       " 'help': 2,\n",
       " 'escape': 1,\n",
       " 'can': 2,\n",
       " 'really': 7,\n",
       " 'wo': 5,\n",
       " 'care.there': 1,\n",
       " 'real': 6,\n",
       " 'skin': 1,\n",
       " 'strips': 1,\n",
       " 'slowly': 1,\n",
       " 'underwear': 1,\n",
       " 'twice': 1,\n",
       " 'rest': 3,\n",
       " 'just': 8,\n",
       " 'boring': 3,\n",
       " 'chockful': 1,\n",
       " 'atrocious': 2,\n",
       " 'comedy': 2,\n",
       " 'never': 7,\n",
       " 'thought': 1,\n",
       " 'funny': 3,\n",
       " 'i': 21,\n",
       " 'know': 7,\n",
       " 'terrible': 1,\n",
       " 'post-dubbed': 1,\n",
       " 'dialogue': 1,\n",
       " 'admit': 1,\n",
       " 'was': 8,\n",
       " 'end': 7,\n",
       " 'did': 2,\n",
       " 'see': 4,\n",
       " 'coming': 1,\n",
       " \"'s\": 3,\n",
       " 'enough': 1,\n",
       " 'sit': 2,\n",
       " 'also': 5,\n",
       " 'attempts': 1,\n",
       " 'hysterical': 1,\n",
       " 'bomb': 1,\n",
       " 'avoid': 1,\n",
       " 'film': 27,\n",
       " 'more': 6,\n",
       " 'effective': 1,\n",
       " 'persuading': 1,\n",
       " 'zionist': 1,\n",
       " 'conspiracy': 1,\n",
       " 'muslim': 1,\n",
       " \"'m\": 4,\n",
       " 'jewish.anbody': 1,\n",
       " 'go': 6,\n",
       " 'journalism': 1,\n",
       " 'school': 1,\n",
       " 'read': 4,\n",
       " 'editorial': 1,\n",
       " 'freshman': 1,\n",
       " 'year': 2,\n",
       " 'rhetoric': 1,\n",
       " 'alarmist': 1,\n",
       " 'assertions': 1,\n",
       " 'presented': 1,\n",
       " 'palatable': 1,\n",
       " 'way': 6,\n",
       " 'might': 1,\n",
       " 'prove': 2,\n",
       " 'persuasive': 1,\n",
       " 'offering': 1,\n",
       " 'acknowledgment': 1,\n",
       " 'possible': 1,\n",
       " 'opposing': 1,\n",
       " 'arguments': 1,\n",
       " 'viable': 1,\n",
       " 'solutions': 1,\n",
       " 'sources': 1,\n",
       " 'dubious': 1,\n",
       " 'origin': 1,\n",
       " 'makes': 6,\n",
       " 'argument': 1,\n",
       " 'ineffectual': 1,\n",
       " 'diatribe.and': 1,\n",
       " 'thank': 1,\n",
       " 'goodness': 1,\n",
       " 'that': 6,\n",
       " 'would': 16,\n",
       " 'want': 3,\n",
       " 'anyone': 1,\n",
       " 'leave': 1,\n",
       " 'theatre': 1,\n",
       " 'believing': 1,\n",
       " 'racist': 1,\n",
       " 'claptrap.a': 1,\n",
       " 'good': 7,\n",
       " 'lesson': 1,\n",
       " 'me': 2,\n",
       " 'hopefully': 1,\n",
       " 'cautionary': 1,\n",
       " 'you': 15,\n",
       " 'actually': 7,\n",
       " 'seeing': 5,\n",
       " 'are': 6,\n",
       " 'already': 4,\n",
       " 'familiar': 1,\n",
       " 'pop': 2,\n",
       " 'stars': 4,\n",
       " 'star': 2,\n",
       " 'save': 1,\n",
       " 'time': 13,\n",
       " 'stop': 1,\n",
       " 'reading': 2,\n",
       " 'review': 2,\n",
       " \"'ve\": 8,\n",
       " 'reached': 1,\n",
       " 'next': 1,\n",
       " 'sentence.forget': 1,\n",
       " 'ever': 7,\n",
       " 'stumbled': 1,\n",
       " 'watch': 2,\n",
       " 'something': 5,\n",
       " 'else.but': 1,\n",
       " 'insist': 1,\n",
       " 'consider': 2,\n",
       " 'lame': 1,\n",
       " 'vehicle': 1,\n",
       " 'japanese': 1,\n",
       " 'teen': 1,\n",
       " 'idol': 1,\n",
       " 'pretty-boys': 1,\n",
       " 'featuring': 2,\n",
       " 'nonsensical': 1,\n",
       " 'convoluted': 1,\n",
       " 'plot': 5,\n",
       " 'drags': 2,\n",
       " 'insufferable': 1,\n",
       " 'amount': 2,\n",
       " \"'re\": 5,\n",
       " 'ready': 1,\n",
       " 'scream.nothing': 1,\n",
       " 'sense': 7,\n",
       " 'endless': 1,\n",
       " 'series': 1,\n",
       " 'people': 13,\n",
       " 'expressing': 1,\n",
       " 'various': 1,\n",
       " 'emotions': 1,\n",
       " 'joy': 1,\n",
       " 'anger': 1,\n",
       " 'happiness': 1,\n",
       " 'tragedy': 1,\n",
       " 'reason': 7,\n",
       " 'incredibly': 1,\n",
       " 'dramatic': 1,\n",
       " 'happening': 2,\n",
       " 'give': 2,\n",
       " 'crap': 3,\n",
       " \"'cause\": 1,\n",
       " 'backstory.by': 1,\n",
       " 'will': 4,\n",
       " 'sick': 1,\n",
       " 'tired': 1,\n",
       " 'stupid': 2,\n",
       " 'lanky': 1,\n",
       " 'girly': 1,\n",
       " 'faces': 2,\n",
       " \"'ll\": 5,\n",
       " 'revolted': 1,\n",
       " 'having': 5,\n",
       " 'spent': 2,\n",
       " 'watching': 5,\n",
       " 'smile': 1,\n",
       " 'sneer': 1,\n",
       " 'cry': 1,\n",
       " 'look': 2,\n",
       " 'mysterious': 1,\n",
       " 'serious': 2,\n",
       " 'pointless': 1,\n",
       " 'expression': 1,\n",
       " 'slap': 1,\n",
       " 'their': 8,\n",
       " 'faces.that': 1,\n",
       " 'moron': 1,\n",
       " 'far': 6,\n",
       " 'refer': 1,\n",
       " 'piece': 1,\n",
       " 'insipid': 1,\n",
       " 'trash': 1,\n",
       " 'soul': 2,\n",
       " 'its': 3,\n",
       " 'actors': 5,\n",
       " 'shadow': 1,\n",
       " 'doubt': 1,\n",
       " 'trailer': 1,\n",
       " 'countless': 1,\n",
       " 'adoring': 1,\n",
       " 'comments': 1,\n",
       " 'site': 1,\n",
       " 'not': 7,\n",
       " 'tell': 1,\n",
       " 'converted': 1,\n",
       " 'mindless': 2,\n",
       " 'minions': 1,\n",
       " 'majority': 1,\n",
       " 'them': 2,\n",
       " 'teenage': 1,\n",
       " 'girls': 1,\n",
       " 'pathological': 1,\n",
       " 'adoration': 1,\n",
       " 'anything': 2,\n",
       " 'androgynous': 1,\n",
       " 'freud': 1,\n",
       " 'field': 1,\n",
       " 'day.unless': 1,\n",
       " 'fans': 2,\n",
       " 'stay': 2,\n",
       " 'hell': 2,\n",
       " 'away': 4,\n",
       " 'abomination': 1,\n",
       " 'europe': 1,\n",
       " 'began': 1,\n",
       " 'fighting': 2,\n",
       " 'world': 4,\n",
       " 'war': 3,\n",
       " 'ii': 1,\n",
       " 'hollywood': 7,\n",
       " 'significant': 1,\n",
       " 'prodding': 1,\n",
       " 'government': 1,\n",
       " 'tons': 1,\n",
       " 'movies': 4,\n",
       " 'were': 3,\n",
       " 'designed': 1,\n",
       " 'try': 1,\n",
       " 'get': 12,\n",
       " 'young': 3,\n",
       " 'men': 4,\n",
       " 'enlist': 1,\n",
       " 'army': 1,\n",
       " 'making': 5,\n",
       " 'life': 6,\n",
       " 'serviceman': 1,\n",
       " 'appear': 3,\n",
       " 'cool': 2,\n",
       " 'sloppiest': 1,\n",
       " 'implying': 1,\n",
       " 'soldier': 1,\n",
       " 'is': 20,\n",
       " 'devoid': 1,\n",
       " 'work': 5,\n",
       " 'best': 4,\n",
       " 'food': 1,\n",
       " 'lie': 1,\n",
       " 'day': 3,\n",
       " 'listening': 1,\n",
       " 'ann': 1,\n",
       " 'miller': 1,\n",
       " 'radio': 1,\n",
       " 'am': 3,\n",
       " 'have': 5,\n",
       " 'participated': 1,\n",
       " 'wwii': 1,\n",
       " 'think': 11,\n",
       " 'there': 4,\n",
       " 'it': 19,\n",
       " 'barest': 1,\n",
       " 'cat': 1,\n",
       " 'whisker': 1,\n",
       " 'bunch': 1,\n",
       " 'musical': 1,\n",
       " 'numbers': 1,\n",
       " 'leading': 2,\n",
       " 'acts.i': 1,\n",
       " 'even': 13,\n",
       " 'most': 7,\n",
       " 'naive': 2,\n",
       " 'civvies': 1,\n",
       " 'knew': 3,\n",
       " 'going': 2,\n",
       " 'overseas': 1,\n",
       " 'wacky': 1,\n",
       " 'hijinks': 1,\n",
       " 'portrayed': 1,\n",
       " 'movie': 38,\n",
       " 'sure': 3,\n",
       " 'meant': 1,\n",
       " 'be': 6,\n",
       " 'viewed': 1,\n",
       " 'escapist': 1,\n",
       " 'entertainment': 2,\n",
       " 'wonder': 3,\n",
       " 'family': 2,\n",
       " 'loved': 2,\n",
       " 'ones': 2,\n",
       " 'amused': 1,\n",
       " 'repulsed': 1,\n",
       " 'trivialization': 1,\n",
       " 'sacrifice': 1,\n",
       " 'im': 1,\n",
       " 'surprised': 1,\n",
       " 'cowgirls': 1,\n",
       " 'blues': 1,\n",
       " 'expected': 2,\n",
       " 'better': 5,\n",
       " 'uma': 1,\n",
       " 'thurman': 1,\n",
       " 'which': 5,\n",
       " 'suffered': 1,\n",
       " 'experience': 1,\n",
       " 'first': 6,\n",
       " 'place': 2,\n",
       " 'awful': 1,\n",
       " 'only': 5,\n",
       " 'music': 2,\n",
       " 'redeeming': 1,\n",
       " 'quality': 1,\n",
       " 'shame': 1,\n",
       " 'we': 3,\n",
       " 'incapable': 1,\n",
       " 'giving': 1,\n",
       " 'reviews': 2,\n",
       " 'deserves': 1,\n",
       " 'found': 3,\n",
       " 'comment': 2,\n",
       " 'useful': 1,\n",
       " 'counting': 1,\n",
       " 'such': 5,\n",
       " 'suckers': 1,\n",
       " 'image': 5,\n",
       " 'looks': 2,\n",
       " 'much': 13,\n",
       " 'intellectually': 1,\n",
       " 'hollow': 2,\n",
       " 'idealism': 2,\n",
       " 'lurks': 1,\n",
       " 'communism': 1,\n",
       " 'che': 10,\n",
       " 'charisma': 1,\n",
       " 'his': 5,\n",
       " 'iconic': 2,\n",
       " 'stature': 1,\n",
       " 'misinformation': 1,\n",
       " 'has': 5,\n",
       " 'spread': 1,\n",
       " 'leftist': 1,\n",
       " 'propaganda': 2,\n",
       " 'him.i': 1,\n",
       " 'do': 6,\n",
       " 'worse': 2,\n",
       " 'captured': 1,\n",
       " 'murder-squads': 1,\n",
       " 'hours': 2,\n",
       " 'typically': 1,\n",
       " 'soderberghian': 1,\n",
       " 'garbage': 3,\n",
       " 'question': 2,\n",
       " 'pet-project': 1,\n",
       " 'took': 2,\n",
       " 'so': 5,\n",
       " 'long': 3,\n",
       " 'referring': 1,\n",
       " 'course': 3,\n",
       " 'left-wing': 1,\n",
       " 'secret': 5,\n",
       " 'love': 6,\n",
       " 'marxist': 1,\n",
       " 'tyrants': 1,\n",
       " 'castro': 3,\n",
       " 'take': 7,\n",
       " 'pick': 1,\n",
       " 'fascinated': 1,\n",
       " 'tinseltown': 1,\n",
       " 'least': 2,\n",
       " 'talented': 1,\n",
       " 'liberal': 1,\n",
       " 'directors': 2,\n",
       " 'finally': 3,\n",
       " 'irresistibly': 1,\n",
       " 'biased': 1,\n",
       " 'project': 1,\n",
       " 'oliver': 1,\n",
       " 'stone': 1,\n",
       " 'years': 2,\n",
       " 'robert': 1,\n",
       " 'redford': 1,\n",
       " 'tim': 1,\n",
       " 'robbins': 1,\n",
       " 'warren': 1,\n",
       " 'beatty': 1,\n",
       " 'alan': 2,\n",
       " 'pakula': 1,\n",
       " 'george': 1,\n",
       " 'clooney': 1,\n",
       " 'barbra': 1,\n",
       " 'streisand': 1,\n",
       " 'mystery': 1,\n",
       " 'overrated': 1,\n",
       " 'artists': 1,\n",
       " 'often': 3,\n",
       " 'indulging': 1,\n",
       " 'similar': 2,\n",
       " 'politically': 1,\n",
       " 'one-sided': 1,\n",
       " 'projects': 1,\n",
       " 'yet': 2,\n",
       " 'somehow': 3,\n",
       " 'guevara': 5,\n",
       " 'arguably': 1,\n",
       " 'popular': 1,\n",
       " 'well-known': 2,\n",
       " 'communist': 1,\n",
       " 'topic': 1,\n",
       " 'theirs': 1,\n",
       " 'guerrilla': 1,\n",
       " 'hallmarks': 1,\n",
       " 'american': 1,\n",
       " 'truth-bending': 1,\n",
       " 'story': 8,\n",
       " 'epic': 1,\n",
       " 'scale': 1,\n",
       " 'as': 1,\n",
       " 'factual': 1,\n",
       " 'detail': 2,\n",
       " 'other': 4,\n",
       " 'big-budget': 1,\n",
       " 'political': 1,\n",
       " 'fairy-tale': 1,\n",
       " 'bios': 1,\n",
       " 'x': 1,\n",
       " 'gandhi': 1,\n",
       " 'i.e': 1,\n",
       " 'almost': 1,\n",
       " 'none': 2,\n",
       " 'del': 4,\n",
       " 'argentinian': 1,\n",
       " 'revolutionary': 1,\n",
       " 'nevertheless': 1,\n",
       " 'however': 2,\n",
       " 'controversial': 1,\n",
       " 'criminal': 1,\n",
       " 'man': 5,\n",
       " 'actions': 2,\n",
       " 'may': 3,\n",
       " 'been': 10,\n",
       " 'thing': 4,\n",
       " 'nobody': 1,\n",
       " 'could': 10,\n",
       " 'him': 3,\n",
       " 'he': 7,\n",
       " 'intelligent': 1,\n",
       " 'manipulator': 1,\n",
       " 'came': 1,\n",
       " 'rich': 1,\n",
       " 'toro': 3,\n",
       " 'fits': 1,\n",
       " 'bill': 1,\n",
       " 'visually': 2,\n",
       " 'interesting': 3,\n",
       " 'charismatic': 1,\n",
       " 'actor': 5,\n",
       " 'resemble': 1,\n",
       " 'physically': 2,\n",
       " 'exudes': 1,\n",
       " 'intellectual': 2,\n",
       " 'qualities': 1,\n",
       " 'hence': 1,\n",
       " 'come': 2,\n",
       " 'primitive': 1,\n",
       " 'casting': 1,\n",
       " 'mediocrities': 1,\n",
       " 'bratt': 1,\n",
       " 'philips': 1,\n",
       " 'franka': 1,\n",
       " 'incompetente': 1,\n",
       " 'underlines': 2,\n",
       " 'director': 4,\n",
       " 'lack': 1,\n",
       " 'sound': 1,\n",
       " 'judgment.the': 1,\n",
       " 'part': 3,\n",
       " 'extremely': 2,\n",
       " 'slow': 1,\n",
       " 'surprise': 2,\n",
       " 'uninteresting': 2,\n",
       " 'brilliant': 1,\n",
       " 'kubrick': 1,\n",
       " 'carefully': 1,\n",
       " 'considered': 1,\n",
       " 'releasing': 1,\n",
       " 'goes': 1,\n",
       " '3-hour': 1,\n",
       " 'mark': 2,\n",
       " 'quite': 3,\n",
       " 'telling': 1,\n",
       " 'soderbergh': 4,\n",
       " 'solid': 1,\n",
       " 'early': 2,\n",
       " 'career': 1,\n",
       " 'oceanic': 1,\n",
       " 'grandness': 1,\n",
       " 'task': 1,\n",
       " 'length': 1,\n",
       " 'indicates': 1,\n",
       " 'bulk': 1,\n",
       " 'shown': 1,\n",
       " 'focuses': 1,\n",
       " 'last': 2,\n",
       " 'phase': 1,\n",
       " 'lot': 2,\n",
       " 'tedious': 1,\n",
       " 'jungle': 1,\n",
       " 'nonsense': 1,\n",
       " 'full': 1,\n",
       " 'alleged': 1,\n",
       " 'psychopaths': 1,\n",
       " 'ideals': 2,\n",
       " 'kind': 5,\n",
       " 'mind': 1,\n",
       " 'highly': 1,\n",
       " 'esteemed': 1,\n",
       " 'choose': 1,\n",
       " 'ignore': 1,\n",
       " 'earlier': 1,\n",
       " 'too': 3,\n",
       " 'massacre': 1,\n",
       " 'holds': 1,\n",
       " 'interest': 1,\n",
       " 'viewer': 1,\n",
       " 'huh': 3,\n",
       " 'amazing': 2,\n",
       " 'over-praised': 1,\n",
       " 'charlatan': 1,\n",
       " 'easily': 1,\n",
       " 'fit': 1,\n",
       " 'complete': 1,\n",
       " 'biographies': 1,\n",
       " 'movie.soderbergh': 1,\n",
       " 'becomes': 1,\n",
       " 'accomplice': 1,\n",
       " 'addressing': 1,\n",
       " 'negative': 1,\n",
       " 'dark': 1,\n",
       " 'side': 1,\n",
       " '%': 3,\n",
       " 'spreading': 1,\n",
       " 'historical': 1,\n",
       " 'inaccuracy': 1,\n",
       " 'consciously': 1,\n",
       " 'ignoring': 1,\n",
       " 'ugly': 1,\n",
       " 'truth': 2,\n",
       " 'god': 2,\n",
       " 'forbid': 1,\n",
       " 'should': 4,\n",
       " 'taint': 1,\n",
       " 'holy': 1,\n",
       " 'proves': 1,\n",
       " 'humanist': 1,\n",
       " 'fake': 1,\n",
       " 'personalities': 1,\n",
       " 'struggle': 1,\n",
       " 'hard': 1,\n",
       " 'careers': 1,\n",
       " 'uphold': 1,\n",
       " 'opposite': 1,\n",
       " 'cares': 1,\n",
       " 'ideas': 2,\n",
       " 'tested': 1,\n",
       " 'guinea': 1,\n",
       " 'pigs': 1,\n",
       " 'elitists': 1,\n",
       " 'worst': 1,\n",
       " 'latent': 1,\n",
       " 'contempt': 1,\n",
       " 'proleteriat': 1,\n",
       " 'term': 1,\n",
       " 'they': 10,\n",
       " 'supposedly': 2,\n",
       " 'siding': 1,\n",
       " 'with.half': 1,\n",
       " 'students': 1,\n",
       " 'wear': 1,\n",
       " 'red': 1,\n",
       " 'orange': 1,\n",
       " 'shirts': 1,\n",
       " 'knowing': 1,\n",
       " 'become': 2,\n",
       " 'figure': 2,\n",
       " 'clueless': 2,\n",
       " 'uninformed': 1,\n",
       " 'face': 2,\n",
       " 'chest': 1,\n",
       " 'edgy': 1,\n",
       " 'hip': 2,\n",
       " 'reality': 1,\n",
       " 'wearing': 2,\n",
       " 'shirt': 1,\n",
       " 'overall': 1,\n",
       " 'shallowness': 1,\n",
       " 'total': 3,\n",
       " 'disinterest': 1,\n",
       " 'self-education': 1,\n",
       " 'find': 3,\n",
       " 'person': 1,\n",
       " 'start': 2,\n",
       " 'advertising': 1,\n",
       " 'his/her': 1,\n",
       " 'by-now': 1,\n",
       " 'clich': 1,\n",
       " 'common': 1,\n",
       " 'bart': 1,\n",
       " 'simpson': 1,\n",
       " 'coffee': 1,\n",
       " 'cup': 1,\n",
       " 'che-wearers': 1,\n",
       " 'probably': 1,\n",
       " 'marge': 1,\n",
       " 'blue': 1,\n",
       " 'hair': 3,\n",
       " 'fidel': 1,\n",
       " 'dead': 2,\n",
       " 'ally.after': 1,\n",
       " 'everything': 3,\n",
       " \"'d\": 3,\n",
       " 'done': 2,\n",
       " 'name': 1,\n",
       " 'marx': 1,\n",
       " 'mongrel': 1,\n",
       " 'laid': 1,\n",
       " 'seems': 2,\n",
       " 'mankind': 1,\n",
       " 'learn': 1,\n",
       " 'stalin': 1,\n",
       " 'mao': 1,\n",
       " 'kim': 1,\n",
       " 'il': 1,\n",
       " 'pol': 1,\n",
       " 'pot': 1,\n",
       " 'milosevic': 1,\n",
       " 'ceausescu': 1,\n",
       " 'iron': 1,\n",
       " 'curtain': 1,\n",
       " 'ruined': 1,\n",
       " 'and/or': 1,\n",
       " 'mentally': 1,\n",
       " 'system': 1,\n",
       " 'matters': 1,\n",
       " 'fact': 2,\n",
       " 'cannes': 2,\n",
       " 'absolutely': 4,\n",
       " 'european': 1,\n",
       " 'festivals': 1,\n",
       " 'vote': 1,\n",
       " 'hint': 1,\n",
       " 'sean': 2,\n",
       " 'penn': 1,\n",
       " 'headed': 1,\n",
       " 'jury': 1,\n",
       " 'ago.for': 1,\n",
       " 'music-related': 1,\n",
       " 'rants': 1,\n",
       " 'http': 1,\n",
       " '//rateyourmusic.com/collection/fedor8/': 1,\n",
       " 'went': 1,\n",
       " 'expecting': 2,\n",
       " \"'nothing\": 1,\n",
       " 'action': 3,\n",
       " 'flick': 2,\n",
       " 'still': 3,\n",
       " 'got': 2,\n",
       " 'disappointed': 1,\n",
       " 'opening': 1,\n",
       " 'scene': 5,\n",
       " 'promised': 1,\n",
       " 'tinge': 1,\n",
       " 'keeps': 1,\n",
       " 'hooked': 1,\n",
       " 'half': 2,\n",
       " 'coz': 1,\n",
       " 'now': 1,\n",
       " 'kick': 1,\n",
       " 'well': 5,\n",
       " 'nothing': 4,\n",
       " 'sort': 1,\n",
       " 'happens': 1,\n",
       " 'ending': 4,\n",
       " 'thumps': 1,\n",
       " 'point': 1,\n",
       " 'thinking': 2,\n",
       " 'watsoever': 1,\n",
       " 'lacked': 1,\n",
       " 'aspects': 1,\n",
       " 'had': 3,\n",
       " 'storyline': 1,\n",
       " 'seemed': 2,\n",
       " 'rambo': 1,\n",
       " 'helped': 1,\n",
       " 'rating': 1,\n",
       " 'simply': 2,\n",
       " 'logic': 1,\n",
       " 'perfect': 1,\n",
       " 'waste': 5,\n",
       " 'money': 3,\n",
       " 'irritating': 1,\n",
       " 'seen': 3,\n",
       " 'b': 1,\n",
       " 'others': 1,\n",
       " 'viewpoint': 1,\n",
       " 'enduring': 1,\n",
       " 'definitely': 1,\n",
       " 'left': 1,\n",
       " 'cast': 3,\n",
       " 'given': 2,\n",
       " 'characters': 1,\n",
       " 'inexplicable': 1,\n",
       " 'many': 6,\n",
       " 'moments': 2,\n",
       " 'unintentional': 1,\n",
       " 'humor': 1,\n",
       " 'killed': 1,\n",
       " 'pierced': 1,\n",
       " 'pieces': 1,\n",
       " 'phonograph': 1,\n",
       " 'record': 1,\n",
       " 'witch': 3,\n",
       " 'drunk': 1,\n",
       " 'hop': 1,\n",
       " 'beat': 1,\n",
       " 'then': 3,\n",
       " 'hit': 1,\n",
       " 'head': 3,\n",
       " 'bottle': 1,\n",
       " 'grabs': 1,\n",
       " 'hostage': 1,\n",
       " 'pouts': 1,\n",
       " 'victim': 1,\n",
       " 'played': 3,\n",
       " 'actress': 1,\n",
       " 'house': 1,\n",
       " 'together': 1,\n",
       " 'sets': 1,\n",
       " 'stooges': 1,\n",
       " 'routine': 1,\n",
       " 'begs': 1,\n",
       " 'woman': 1,\n",
       " 'does': 2,\n",
       " 'instead': 2,\n",
       " 'elaborate': 1,\n",
       " 'chase': 1,\n",
       " 'missed': 1,\n",
       " 'christopher': 1,\n",
       " 'walkin': 1,\n",
       " 'eyeglasses': 1,\n",
       " 'automotive': 1,\n",
       " 'explanation': 1,\n",
       " 'afterlife': 2,\n",
       " 'paraphrased': 1,\n",
       " 'ancient': 1,\n",
       " 'wee': 1,\n",
       " 'materialists': 1,\n",
       " 'body': 1,\n",
       " 'eternity': 1,\n",
       " 'used': 2,\n",
       " 'car': 2,\n",
       " 'souped': 1,\n",
       " 'druids': 1,\n",
       " 'drive': 1,\n",
       " 'walk': 1,\n",
       " 'indecipherable': 1,\n",
       " 'ran': 2,\n",
       " 'kept': 1,\n",
       " 'vomiting': 1,\n",
       " 'freak': 1,\n",
       " 'usually': 4,\n",
       " 'appears': 1,\n",
       " 'tv': 3,\n",
       " 'main': 5,\n",
       " 'like': 2,\n",
       " 'about': 1,\n",
       " 'value': 1,\n",
       " 'getting': 1,\n",
       " 'root': 1,\n",
       " 'canal': 1,\n",
       " 'approaches': 1,\n",
       " 'abyssmal': 1,\n",
       " 'depths': 1,\n",
       " 'gets': 3,\n",
       " 'describing': 1,\n",
       " 'further': 1,\n",
       " 'suffice': 1,\n",
       " 'say': 1,\n",
       " 'pity': 1,\n",
       " 'poor': 1,\n",
       " 'camera': 2,\n",
       " 'suffer': 1,\n",
       " 'c**p': 1,\n",
       " 'watched': 3,\n",
       " 'minutes': 5,\n",
       " 'ago': 1,\n",
       " 'idea': 3,\n",
       " 'mainly': 1,\n",
       " 'internet': 1,\n",
       " 'cd': 2,\n",
       " 'roms': 2,\n",
       " 'realistic': 2,\n",
       " 'flash': 1,\n",
       " 'cartoons': 1,\n",
       " 'online': 1,\n",
       " 'murdered': 1,\n",
       " 'someone': 2,\n",
       " 'causes': 1,\n",
       " 'sister': 1,\n",
       " 'crack': 2,\n",
       " 'team': 2,\n",
       " 'fbi': 1,\n",
       " 'agents': 1,\n",
       " 'investigate': 1,\n",
       " 'death': 1,\n",
       " 'local': 1,\n",
       " 'homicide': 1,\n",
       " 'division': 1,\n",
       " 'big': 2,\n",
       " 'city': 1,\n",
       " 'usa': 1,\n",
       " 'investigating': 1,\n",
       " 'comes': 1,\n",
       " 'oogling': 1,\n",
       " 'claims': 1,\n",
       " 'wow.michael': 1,\n",
       " 'madsen': 2,\n",
       " 'credits': 1,\n",
       " 'banging': 1,\n",
       " 'girl': 2,\n",
       " 'seemingly': 1,\n",
       " 'apparent': 1,\n",
       " 'explain': 2,\n",
       " 'frankly': 1,\n",
       " 'make': 5,\n",
       " 'final': 2,\n",
       " 'treated': 1,\n",
       " 'minute': 1,\n",
       " 'montage': 1,\n",
       " 'honestly': 1,\n",
       " 'same': 1,\n",
       " 'effect': 1,\n",
       " 'cross': 1,\n",
       " 'eyed': 1,\n",
       " 'direction': 1,\n",
       " 'all.all': 1,\n",
       " 'michael': 1,\n",
       " 'else': 3,\n",
       " 'satisfied': 1,\n",
       " 'playing': 1,\n",
       " 'game': 1,\n",
       " 'knife': 1,\n",
       " 'jab': 1,\n",
       " 'your': 1,\n",
       " 'hand': 1,\n",
       " 'repeatedly': 1,\n",
       " 'entertaining': 1,\n",
       " 'reasons': 2,\n",
       " 'malcolm': 1,\n",
       " 'mcdowell': 1,\n",
       " 'gwynyth': 1,\n",
       " 'walsh': 1,\n",
       " 'tried': 2,\n",
       " 'play': 1,\n",
       " 'level': 1,\n",
       " 'scenes': 3,\n",
       " 'blocked': 1,\n",
       " 'scripting.the': 1,\n",
       " 'looking': 3,\n",
       " 'cyborg': 1,\n",
       " 'different': 2,\n",
       " 'roles': 2,\n",
       " 'far.everything': 1,\n",
       " 'useless': 1,\n",
       " 'dialogs': 1,\n",
       " 'script': 2,\n",
       " 'failed': 1,\n",
       " 'completely': 3,\n",
       " 'attic': 3,\n",
       " 'set': 1,\n",
       " 'inspired': 1,\n",
       " 'true': 1,\n",
       " 'unfortunately': 1,\n",
       " 'need': 2,\n",
       " 'told.looking': 1,\n",
       " 'box': 2,\n",
       " 'responsible': 1,\n",
       " 'packaging': 1,\n",
       " 'steamy': 1,\n",
       " 'erotic': 1,\n",
       " 'use': 2,\n",
       " 'terms': 1,\n",
       " 'illicit': 1,\n",
       " 'passion': 1,\n",
       " 'forbidden': 1,\n",
       " 'affair': 2,\n",
       " 'unlimited': 1,\n",
       " 'pleasures': 1,\n",
       " 'picture': 3,\n",
       " 'neil': 1,\n",
       " 'patrick': 1,\n",
       " 'harris': 2,\n",
       " 'doogie': 1,\n",
       " 'howser': 1,\n",
       " 'm.d': 1,\n",
       " 'holding': 1,\n",
       " 'gun': 1,\n",
       " 'involves': 1,\n",
       " 'krista': 5,\n",
       " 'archer': 1,\n",
       " 'unhappily': 1,\n",
       " 'married': 1,\n",
       " 'gentleman': 1,\n",
       " 'owns': 1,\n",
       " 'own': 2,\n",
       " 'business': 1,\n",
       " 'edward': 4,\n",
       " 'employee': 1,\n",
       " 'husband': 2,\n",
       " 'company': 1,\n",
       " 'falling': 1,\n",
       " 'other.the': 1,\n",
       " 'shocking': 1,\n",
       " 'finds': 1,\n",
       " 'forbids': 1,\n",
       " 'decide': 1,\n",
       " 'ends': 3,\n",
       " 'live': 2,\n",
       " 'wow': 1,\n",
       " 'jealous': 1,\n",
       " 'cover': 1,\n",
       " 'new': 3,\n",
       " 'territory': 1,\n",
       " 'showtime': 1,\n",
       " 'original': 2,\n",
       " 'explains': 1,\n",
       " 'couple': 1,\n",
       " 'b-list': 1,\n",
       " 'buff': 1,\n",
       " 'sleepless': 1,\n",
       " 'night': 1,\n",
       " 'switching': 1,\n",
       " 'channels': 1,\n",
       " 'embarrassment': 1,\n",
       " 'remote': 1,\n",
       " 'control': 1,\n",
       " 'kari': 1,\n",
       " 'wuhrer': 1,\n",
       " 'salin': 1,\n",
       " 'gone': 1,\n",
       " 'nowhere.and': 1,\n",
       " 'david': 2,\n",
       " 'keith': 2,\n",
       " 'role': 1,\n",
       " 'pathetic': 1,\n",
       " 'anyway': 1,\n",
       " 'turned': 1,\n",
       " 'must': 2,\n",
       " 'nerdy': 1,\n",
       " 'college': 1,\n",
       " 'kid': 2,\n",
       " 'brings': 1,\n",
       " 'home': 1,\n",
       " 'dominatrix-ish': 1,\n",
       " 'straight': 1,\n",
       " 'comic': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 198,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_word = {} # Création d'un dictionnaire pour supprimer tous les mots qui n'aparaissent qu'une fois ou trop de fois\n",
    "nb = 0 # Nombre de mot total\n",
    "\n",
    "for i in range(0, len(dfc_phrases_clear), 1):\n",
    "    for j in range(0, len(dfc_phrases_clear[i]), 1):\n",
    "        for word in dfc_phrases_clear[i][j]:\n",
    "            if word not in dic_word:\n",
    "                dic_word[word] = 1\n",
    "            else:\n",
    "                dic_word[word] += 1\n",
    "            nb+=1\n",
    "\n",
    "\n",
    "display(dic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille dico avant 1451 et après 382\n"
     ]
    }
   ],
   "source": [
    "KEEPWORD = [] # Liste avec les mots à garder créée grâce au dico\n",
    "\n",
    "for key, value in dic_word.items() :\n",
    "    #display(key)\n",
    "    if ((value > 1) and (value < (nb/25))) :\n",
    "        KEEPWORD.append(key)\n",
    "#display(KEEPWORD)\n",
    "\n",
    "print(\"Taille dico avant \" + str(len(dic_word)) + \" et après \" + str(len(KEEPWORD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Petite fonction pour virer les raccourcis de langage\n",
    "Rdico = {'y':'why', 'u':'you','sux':'suck','asap':'As soon as possible','jk':'joke', 'ur' : 'You are', 'r' : 'are'} \n",
    "\n",
    "def replaceW(word):\n",
    "    for key,value in Rdico.items() :\n",
    "        if word == key :\n",
    "            return value\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Maintenant on les vire de nos commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "[['mediocre', 'sci-fi', 'channel', 'original', 'picture'], ['little', 'squirmish', 'much'], ['nuclear', 'powered', 'submarine', 'u.s.s'], ['jimmy', 'carter', 'mission', 'deep', 'thick', 'frigid', 'ice', 'north', 'pole', 'it', 'attacked', 'giant', 'super', 'charged', 'electric', 'eels'], ['member', 'crew', 'simmone', 'jade', 'mackinnon', 'thinks', 'has', 'devised', 'way', 'communicate', 'monsters', 'not', 'given', 'much', 'chance', 'vague', 'reasons'], ['also', 'crew', 'david', 'keith', 'mark', 'sheppard', 'sean', 'whalen'], ['movie', 'could', 'been', 'somewhat', 'better', 'eels/monsters', 'not', 'cartoonish']]\n",
      "After\n",
      "[['original', 'picture'], [], [], ['charged'], ['member', 'crew', 'thinks', 'reasons'], ['crew', 'david', 'keith', 'mark', 'sean'], ['movie']]\n"
     ]
    }
   ],
   "source": [
    "dfc_clean = dfc_phrases_clear.copy()\n",
    "\n",
    "print(\"Before\")\n",
    "print(dfc_clean[19])\n",
    "\n",
    "for i in range(0, len(dfc_clean), 1):\n",
    "    for j in range(0, len(dfc_clean.loc[i]), 1):\n",
    "        dfc_clean[i][j] = ([replaceW(word) for word in dfc_clean[i][j] if ((word in KEEPWORD)and (word not in STOPWORDS))])\n",
    "        # Nouveau df sans les stopword et avec seulement les mots définis à garder\n",
    "\n",
    "\n",
    "print(\"After\")\n",
    "print(dfc_clean[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Gestion de la négation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "https://www.youtube.com/watch?v=88yOCX4ZyoA&list=PLcTXcpndN-Sl9eYrKM6jtcOTgC52EJnqH&index=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Relation entre les mots : N-Grams tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Une fois que nos data ont subit tous les pré-traitements, créer un nouveau fichier avec les données néttoyées pour permettre l'application de bag of Words. </br>\n",
    "Peut être que les bag of words ne sont à appliquer que sur les mots les plus significatifs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "with open (\"./Data/dataset.csv\", \"r\") as file:\n",
    "    X_train_counts = count_vect.fit_transform(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "display(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "display(X_train_counts.todense() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}